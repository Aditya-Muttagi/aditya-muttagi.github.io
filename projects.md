---
layout: page
title: "Case Studies"
permalink: /projects/
---

<span class="page-eyebrow">Product & Data Analytics</span>

Each case study follows the same pattern: <strong>context → approach → impact</strong>.  
You can replace the placeholder details below with your real projects as you build them.

<div class="project-grid">

  <article class="project-card" id="activation-case-study">
    <p class="project-tag">Feature Adoption</p>
    <h2 class="project-title">Improving New User Activation</h2>
    <p class="project-meta">Sample case – replace with your real project</p>

    <p><strong>Context</strong></p>
    <p>
      New users were signing up but not meaningfully using a core feature in the
      first week. The product team wanted to understand where the friction was
      and what “activation” should actually mean.
    </p>

    <p><strong>Approach</strong></p>
    <ul>
      <li>Defined an activation event tied to real product value (not just log-in)</li>
      <li>Built a simple journey from sign-up → onboarding → first key action</li>
      <li>Segmented activation rate by device, channel and onboarding path</li>
      <li>Reviewed event tracking and proposed a cleaner event schema</li>
    </ul>

    <p class="project-outcome"><strong>Impact</strong></p>
    <p>
      Produced a clear activation metric and identified 2–3 friction points in
      onboarding for experimentation (e.g., copy changes, nudges, streamlined
      steps). <em>When you have numbers, replace this with real uplift or learnings.</em>
    </p>
  </article>

  <article class="project-card" id="funnel-case-study">
    <p class="project-tag">Conversion Funnel</p>
    <h2 class="project-title">Sign-up to Subscription Funnel Deep-Dive</h2>
    <p class="project-meta">Sample case – replace with your real project</p>

    <p><strong>Context</strong></p>
    <p>
      The product had healthy traffic and sign-ups but weak conversion to paid
      subscription. The goal was to quantify drop-offs at each step and find
      where to focus UX and experimentation efforts.
    </p>

    <p><strong>Approach</strong></p>
    <ul>
      <li>Broke the journey into discrete steps with clear entry/exit criteria</li>
      <li>Built funnel views overall and sliced by device, channel and cohort</li>
      <li>Highlighted steps with both high drop-off and high volume</li>
      <li>Suggested a short list of A/B test ideas for the worst steps</li>
    </ul>

    <p class="project-outcome"><strong>Impact</strong></p>
    <p>
      Delivered a prioritised funnel view that let the team focus on the
      highest-leverage step first. <em>Swap this with real impact: e.g., projected
      conversion gain or results from launched experiments.</em>
    </p>
  </article>

  <article class="project-card" id="retention-case-study">
    <p class="project-tag">Retention & Cohorts</p>
    <h2 class="project-title">Cohort-Based Retention Analysis</h2>
    <p class="project-meta">Sample case – replace with your real project</p>

    <p><strong>Context</strong></p>
    <p>
      The team wanted to move away from looking only at monthly active users and
      instead understand how retention behaved by cohort and acquisition source.
    </p>

    <p><strong>Approach</strong></p>
    <ul>
      <li>Built cohort tables (sign-up month vs week N activity)</li>
      <li>Plotted retention curves and compared by acquisition channel</li>
      <li>Looked at early behaviours that correlated with long-term retention</li>
      <li>Identified gaps in instrumentation and proposed new events to track</li>
    </ul>

    <p class="project-outcome"><strong>Impact</strong></p>
    <p>
      Gave the team a clearer view of retention quality, not just volume, and
      pointed to early behaviours and channels that were worth investing in.
      <em>Replace with your own numbers or key learnings.</em>
    </p>
  </article>

</div>
